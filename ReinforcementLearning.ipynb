{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKPz7b46yETJJDRwkYWUJK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PkwPanu/Model/blob/main/ReinforcementLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qgvcbQWb-XC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the state space\n",
        "states = ['low_season', 'high_season', 'sunny_day', 'rainy_day', 'popular_attraction', 'less_popular_attraction']\n",
        "num_states = len(states)\n",
        "\n",
        "# Define the action space\n",
        "actions = ['increase_price', 'decrease_price', 'maintain_price']\n",
        "num_actions = len(actions)\n",
        "\n",
        "# Define the reward function\n",
        "def get_reward(state, action):\n",
        "    # This is just an example function - the actual reward function would depend on the specific problem at hand\n",
        "    if state == 'high_season' and action == 'decrease_price':\n",
        "        return -1\n",
        "    elif state == 'low_season' and action == 'increase_price':\n",
        "        return -1\n",
        "    elif state == 'rainy_day':\n",
        "        return 0.5\n",
        "    else:\n",
        "        return 1\n",
        "\n",
        "# Define the Q-table\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Define the hyperparameters\n",
        "alpha = 0.1 # learning rate\n",
        "gamma = 0.9 # discount factor\n",
        "epsilon = 0.1 # exploration rate\n",
        "\n",
        "# Define the epsilon-greedy policy\n",
        "def epsilon_greedy_policy(state):\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        # Explore\n",
        "        action = np.random.choice(range(num_actions))\n",
        "    else:\n",
        "        # Exploit\n",
        "        q_values = q_table[state, :]\n",
        "        max_q_value = np.max(q_values)\n",
        "        actions_with_max_q_value = np.where(q_values == max_q_value)[0]\n",
        "        action = np.random.choice(actions_with_max_q_value)\n",
        "    return action\n",
        "\n",
        "# Train the Q-learning agent\n",
        "num_episodes = 1000\n",
        "for episode in range(num_episodes):\n",
        "    state = np.random.randint(0, num_states)\n",
        "    done = False\n",
        "    while not done:\n",
        "        action = epsilon_greedy_policy(state)\n",
        "        print(state,action)\n",
        "        reward = get_reward(states[state], actions[action])\n",
        "        next_state = np.random.randint(0, num_states)\n",
        "        q_value = q_table[state, action]\n",
        "        next_q_values = q_table[next_state, :]\n",
        "        max_next_q_value = np.max(next_q_values)\n",
        "        td_target = reward + gamma * max_next_q_value\n",
        "        td_error = td_target - q_value\n",
        "        q_table[state, action] += alpha * td_error\n",
        "        state = next_state\n",
        "        if state == num_states - 1:\n",
        "            done = True\n",
        "\n",
        "# Use the learned Q-table to make pricing decisions\n",
        "state = np.random.randint(0, num_states)\n",
        "action = np.argmax(q_table[state, :])\n",
        "print(\"State: \", states[state])\n",
        "print(\"Action: \", actions[action])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the learned Q-table to make pricing decisions\n",
        "state = np.random.randint(0, num_states)\n",
        "action = np.argmax(q_table[state, :])\n",
        "print(\"State: \", states[state])\n",
        "print(\"Action: \", actions[action])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BP1jRP2yPpCg",
        "outputId": "27981749-42a8-4bdc-9d81-a12afda07c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "State:  sunny_day\n",
            "Action:  decrease_price\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RL for path finding**"
      ],
      "metadata": {
        "id": "6ABaSNUokld-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# define the grid world game environment\n",
        "num_rows = 10\n",
        "num_cols = 10\n",
        "start_state = (1, 1)\n",
        "goal_state  = (8, 8)\n",
        "obsctruct_num=20\n",
        "invalid_states=[(i,j) for i,j in zip(np.random.randint(0,num_cols,obsctruct_num),np.random.randint(0,num_rows,obsctruct_num))]\n",
        "invalid_states = invalid_states+[(0, j) for j in range(num_rows) ] + [(num_cols-1, j) for j in range(num_rows)]+[( j, 0) for j in range(num_cols)]+[( j, num_rows-1) for j in range(num_cols)]\n",
        "\n",
        "map=np.zeros([num_rows,num_cols])\n",
        "map[start_state]= 1\n",
        "map[goal_state] = 1\n",
        "for x in invalid_states:\n",
        "  map[x] = 0.5\n",
        "plt.imshow(map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "KqC3qPbZSs_j",
        "outputId": "6790dcbc-fe04-4498-ed70-17c5b4c25030"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fca164a0250>"
            ]
          },
          "metadata": {},
          "execution_count": 176
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the reward function\n",
        "def get_reward(state, action):\n",
        "    \"\"\"\n",
        "    Returns the reward for taking an action in a given state.\n",
        "    \"\"\"\n",
        "    if is_goal_state(state, action):\n",
        "        return 1000\n",
        "    elif is_invalid_state(state, action):\n",
        "        return -100\n",
        "    else:\n",
        "        return -1\n",
        "\n",
        "# define helper functions for the reward function\n",
        "def is_goal_state(state, action):\n",
        "    new_state = take_action(state, action)\n",
        "    return new_state == goal_state\n",
        "\n",
        "def is_invalid_state(state, action):\n",
        "    new_state = take_action(state, action)\n",
        "    return new_state in invalid_states\n",
        "\n",
        "def take_action(state, action):\n",
        "    row, col = state\n",
        "    if action == \"up\":\n",
        "        row = max(row - 1, 0)\n",
        "    elif action == \"down\":\n",
        "        row = min(row + 1, num_rows - 1)\n",
        "    elif action == \"left\":\n",
        "        col = max(col - 1, 0)\n",
        "    elif action == \"right\":\n",
        "        col = min(col + 1, num_cols - 1)\n",
        "    return (row, col)\n",
        "\n",
        "# define the Q-learning algorithm\n",
        "def q_learning(num_episodes, alpha, gamma, epsilon):\n",
        "    # initialize Q values to 0\n",
        "    q_values = np.zeros((num_rows, num_cols, 4))\n",
        "    episode_suc=0\n",
        "    for episode in range(num_episodes):\n",
        "        # initialize state and episode length\n",
        "        state = start_state\n",
        "        done = False\n",
        "        t = 0       \n",
        "        # choose action using exploitation \n",
        "        if np.random.uniform() < epsilon:\n",
        "            action = np.random.choice(action_choice)\n",
        "        else:       \n",
        "            action = action_choice[np.argmax(q_values[state[0], state[1], :])]     \n",
        "        while not done:\n",
        "            # take action and get reward\n",
        "            next_state = take_action(state, action)\n",
        "            reward = get_reward(state, action)\n",
        "            \n",
        "            # choose next action using epsilon-greedy policy\n",
        "            if np.random.uniform() < epsilon:\n",
        "                next_action = np.random.choice(action_choice)\n",
        "            else:\n",
        "                next_action = action_choice[np.argmax(q_values[next_state[0], next_state[1], :])]\n",
        "            # update Q value'\n",
        "            action_id=action_choice.index(action)   \n",
        "            q_values[state[0], state[1], action_id] += alpha * (reward + gamma * q_values[next_state[0], next_state[1], action_choice.index(next_action)] - q_values[state[0], state[1], action_id])    \n",
        "            # update state and action\n",
        "            state = next_state\n",
        "            action = next_action\n",
        "            if (state == goal_state):\n",
        "              episode_suc+=1\n",
        "            # check if goal state is reached or maximum episode length is exceeded\n",
        "            done = (state == goal_state) or (t >= 500)\n",
        "            t += 1\n",
        "\n",
        "    print(episode_suc)\n",
        "    return q_values\n",
        "    \n",
        "\n",
        "action_choice= [\"up\", \"down\", \"left\", \"right\"]\n",
        "\n",
        "# run the Q-learning algorithm for 1000 episodes\n",
        "q_values = q_learning(num_episodes=1000, alpha=0.5, gamma=0.1, epsilon=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV_AijyHklMO",
        "outputId": "5ac1176b-4975-41f3-9345-37125d57bde6"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "770\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "map=np.zeros([num_rows,num_cols])\n",
        "map[start_state]= 1\n",
        "map[goal_state] = 1\n",
        "for x in invalid_states:\n",
        "  map[x] = 0.5\n",
        "plt.imshow(map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "0a3UEKn0WfBX",
        "outputId": "b9c57d9d-6895-45a9-ff5f-40ff3f9a404d"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fca163d5790>"
            ]
          },
          "metadata": {},
          "execution_count": 178
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "state=start_state\n",
        "done = False\n",
        "i=1\n",
        "while not done:\n",
        "  i+=0.1\n",
        "  action=action_choice[np.argmax(q_values[state[0],state[1], :])]\n",
        "  state=take_action(state,action)\n",
        "  map[state]=i\n",
        "  done = (state==goal_state) "
      ],
      "metadata": {
        "id": "3gA0JDns1dy-"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Yc7KPbsfLexB",
        "outputId": "10b596c6-77ca-4d5b-e9b1-d0d18a880632"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fca163bba60>"
            ]
          },
          "metadata": {},
          "execution_count": 180
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}